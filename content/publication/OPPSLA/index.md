---
title: "One Pixel Adversarial Attacks via Sketched Programs"
subtitle: ""
publication_types:
  - "1"
authors:
  - Tom Yuviler
  - Dana Drachsler-Cohen
author_notes:
#  - Technion - Israel Institute of Technology
doi: '10.1145/3591301'
publication: "*PLDI 2023*"
publication_short: ""
url_pdf: "https://dl.acm.org/doi/pdf/10.1145/3591301"
abstract: "Neural networks are successful in various tasks but are also susceptible to adversarial examples. An adversarial example is generated by adding a small perturbation to a correctly-classified input with the goal of causing a network classifier to misclassify. In one pixel attacks, an attacker aims to fool an image classifier by modifying a single pixel. This setting is challenging for two reasons: the perturbation region is very small and the perturbation is not differentiable. To cope, one pixel attacks iteratively generate candidate adversarial examples and submit them to the network until finding a successful candidate. However, existing works require a very large number of queries, which is infeasible in many practical settings, where the attacker is limited to a few thousand queries to the network. We propose a novel approach for computing one pixel attacks. The key idea is to leverage program synthesis and identify an expressive program sketch that enables to compute adversarial examples using significantly fewer queries. We introduce OPPSLA, a synthesizer that, given a classifier and a training set, instantiates the sketch with customized conditions over the input’s pixels and the classifier’s output. OPPSLA employs a stochastic search, inspired by the Metropolis-Hastings algorithm, that synthesizes typed expressions enabling minimization of the number of queries to the classifier. We further show how to extend OPPSLA to compute few pixel attacks minimizing the number of perturbed pixels. We evaluate OPPSLA on several deep networks for CIFAR-10 and ImageNet. We show that OPPSLA obtains a state-of-the-art success rate, often with an order of magnitude fewer queries than existing attacks. We further show that OPPSLA’s programs are transferable to other classifiers, unlike existing one pixel attacks,
which run from scratch on every classifier and input."
draft: false
featured: false
tags:
  - OPPSLA
categories: [OPPSLA]
projects:
  - OPPSLA
summary: ""
lastmod: 2023-06-02T20:08:13+03:00
image:
  filename: featured.png
  caption: "Adversarial Program"
  focal_point: ""
  preview_only: false
date: 2023-06-06
publishDate: 2023-06-02T17:08:13.460963Z
---
